{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Saving and loading models__\n",
    "\n",
    "1. [Load tools](#Load-tools)\n",
    "1. [Saving and loading models](#Saving-and-loading-models)\n",
    "1. [What is a state_dict?](#What-is-a-state_dict?)\n",
    "1. [Saving & loading model for inference](#Saving-&-loading-model-for-inference)\n",
    "1. [Saving & loading a general checkpoint](#Saving-&-loading-a-general-checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Load tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<a id = 'Load-tools'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-02T12:50:01.242507Z",
     "start_time": "2019-05-02T12:50:00.336323Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Standard libary and settings\n",
    "import os\n",
    "import sys\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "from IPython.core.display import display, HTML; display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "\n",
    "# Data extensions and settings\n",
    "import numpy as np\n",
    "np.set_printoptions(threshold = np.inf, suppress = True)\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.options.display.float_format = '{:,.6f}'.format\n",
    "\n",
    "# import PyTorch\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch. autograd as autograd\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.jit import script, trace\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Visualization extensions and settings\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Magic functions\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Saving and loading models\n",
    "\n",
    "There are three core functions:\n",
    "\n",
    "1. torch.save - saves a serialzied object to disk. This uses pickle for serialization. Models, Tensors and dictionaries can be saved using this function.\n",
    "\n",
    "2. torch.load - Uses pickle to deserialize pickled objects.\n",
    "\n",
    "3. torch.nn.Module.load_state_dict - Loads a model's parameter dciontary.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<a id = 'Saving-and-loading-models'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is a state_dict?\n",
    "\n",
    "The torch.nn.Module learnable parameters are contained in the model's parameters (accessed via model.parameters(). A state_dict is a simple Python dictionary that maps each model layer to its parameter tensor. Only layers with learnable parameters have entries in the model's state_dict.\n",
    "\n",
    "Optimizer objects (torch.optim) also have a state_dict that contains information about the optimizer's state and the hyperparameters used.\n",
    "\n",
    "Since the state_dicts are just python dictionaries, they can easily be saved, restored, updated and changed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'What-is-a-state_dict?'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model's state_dict:\n",
      "\n",
      "conv1.weight \t torch.Size([6, 3, 5, 5])\n",
      "conv1.bias \t torch.Size([6])\n",
      "conv2.weight \t torch.Size([16, 6, 5, 5])\n",
      "conv2.bias \t torch.Size([16])\n",
      "fc1.weight \t torch.Size([120, 400])\n",
      "fc1.bias \t torch.Size([120])\n",
      "fc2.weight \t torch.Size([84, 120])\n",
      "fc2.bias \t torch.Size([84])\n",
      "fc3.weight \t torch.Size([10, 84])\n",
      "fc3.bias \t torch.Size([10])\n",
      "\n",
      "optimizer's state_dict:\n",
      "\n",
      "state \t {}\n",
      "param_groups \t [{'lr': 0.001, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [2106751666000, 2106751665640, 2106755451640, 2106751664920, 2106751665208, 2106751666072, 2106751665856, 2106751665928, 2106751665280, 2106755268680]}]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "class TheModelClass(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TheModelClass, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)        \n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "model = TheModelClass()\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.001, momentum = 0.9)\n",
    "\n",
    "print('model\\'s state_dict:\\n')\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, '\\t', model.state_dict()[param_tensor].size())\n",
    "    \n",
    "print('\\noptimizer\\'s state_dict:\\n')\n",
    "for var_tensor in optimizer.state_dict():\n",
    "    print(var_tensor, '\\t', optimizer.state_dict()[var_tensor])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving & loading model for inference\n",
    "\n",
    "A common PyTorch convention is to save models using either a .pt or .pth file extension. When saving a model for inference, only the model's learned parameters are needed. In order to run the model for inference based on the saved parameters, model.evalu() needs to be called in order to set any dropout and batch normalization layers to evaluation mode.\n",
    "\n",
    "The load_state_dict() method takes a dictionary, not a path. The saved state_dict needs to be deserialized before it is passed to load_state_dict().\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Saving-&-loading-model-for-inference'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "torch.save(model.state_dict(), 'saved_model_params_1.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load\n",
    "model = TheModelClass()\n",
    "model.load_state_dict(torch.load('saved_model_params_1.pth'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\petersont\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\torch\\serialization.py:256: UserWarning: Couldn't retrieve source code for container of type TheModelClass. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "# save entire model\n",
    "torch.save(model, 'saved_model_1.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load entire model\n",
    "model = torch.load('saved_model_1.pth')\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving & loading a general checkpoint\n",
    "\n",
    "This process can be used to save a checkpoint for inference and/or resuming training. In this case, it is important to save the optimizer's state_dict in addition to the model's state_dict. Other objects to save may include the last epoch completed, the latest recorded training loss, any torch.nn.Embedding layers, and so on.\n",
    "\n",
    "Saving multiple components can be accomplished by passing the objects into torch.save() using a dictionary. This type of check point is typically stored as a .tar file.\n",
    "\n",
    "```python\n",
    "torch.save({'epoch' : epoch\n",
    "           ,'model_State_dict' : model.state_dict()\n",
    "           ,'optimizer_state_dict' : optimizer.state_dict()\n",
    "           ,'loss' : loss\n",
    "           }, 'saved_ckpt_1.tar')\n",
    "```\n",
    "\n",
    "To load the saved items, the model and optimizer need to be initialized, then the dictionary can be restored using torch.load()\n",
    "\n",
    "```python\n",
    "model = TheModelClass()\n",
    "optimizer = TheOptimizerClass()\n",
    "\n",
    "checkpoint = torch.load('saved_ckpt_1.tar')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']\n",
    "```\n",
    "\n",
    "For inference mode, run model.eval() as before. To resume training, simply call model.train() to put all layers in training mode.\n",
    "\n",
    "```python\n",
    "model.eval()\n",
    "# or\n",
    "model.train()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Saving-&-loading-a-general-checkpoint'></a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
