{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-23T21:51:07.267980Z",
     "start_time": "2018-06-23T21:51:07.263716Z"
    }
   },
   "source": [
    "# TOC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Lab 06 - Text analysis__\n",
    "1. [Import](#Import)\n",
    "1. [Representing text as numberal data](#Representing-text-as-numberal-data)\n",
    "    1. [Example 1 - learn a small vocabulary](#learn-a-small-vocabulary-Example1)\n",
    "1. [Case study - text message analysis](#Case-study-text-message-analysis)\n",
    "    1. [Classify with multinomial naive bayes](#Classify-with-multinomial-naive-bayes)\n",
    "    1. [Classify with logistic regression](#Classify-with-logistic-regression)\n",
    "1. [Parameter tuning w/ CountVectorizer](#Parameter-tuning-w/-CountVectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"Import\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-27T14:18:44.275987Z",
     "start_time": "2019-06-27T14:18:43.239177Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as pd\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set(style=\"whitegrid\", font_scale=1.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Representing text as numberal data\n",
    "\n",
    "Text data can be represented as numberal data by tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"Representing-text-as-numberal-data\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example - learn a small vocabulary\n",
    "\n",
    "Text data can be represented as numberal data by 'tokenized'\n",
    "- Tokenize the vocabulary learned from a small set of training data\n",
    "- Transform a test string based on the training vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"learn-a-small-vocabulary-Example1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-27T14:18:44.294592Z",
     "start_time": "2019-06-27T14:18:44.282213Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "simple_train = [\"call you tonight\", \"Call me a cab\", \"please call me... PLEASE!\"]\n",
    "vect = CountVectorizer()\n",
    "\n",
    "# learn the 'vocabulary' of the training data\n",
    "vect.fit(simple_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-27T14:18:44.339571Z",
     "start_time": "2019-06-27T14:18:44.305142Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cab', 'call', 'me', 'please', 'tonight', 'you']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect\n",
    "vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-27T14:18:44.376214Z",
     "start_time": "2019-06-27T14:18:44.344150Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cab</th>\n",
       "      <th>call</th>\n",
       "      <th>me</th>\n",
       "      <th>please</th>\n",
       "      <th>tonight</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cab  call  me  please  tonight  you\n",
       "0    0     1   0       0        1    1\n",
       "1    1     1   1       0        0    0\n",
       "2    0     1   1       2        0    0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# represent each sample in DataFrame\n",
    "simple_train_dtm = vect.transform(simple_train)\n",
    "simple_train_dtm.toarray()\n",
    "\n",
    "pd.DataFrame(simple_train_dtm.toarray(), columns=vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-27T14:18:44.459734Z",
     "start_time": "2019-06-27T14:18:44.384367Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cab</th>\n",
       "      <th>call</th>\n",
       "      <th>me</th>\n",
       "      <th>please</th>\n",
       "      <th>tonight</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cab  call  me  please  tonight  you\n",
       "0    0     1   1       1        0    0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenize test data string\n",
    "simpleTest = [\"please don't call me\"]\n",
    "\n",
    "simple_test_dtm = vect.transform(simpleTest)\n",
    "simple_test_dtm.toarray()\n",
    "\n",
    "pd.DataFrame(simple_test_dtm.toarray(), columns=vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Notice that the word \"don't\" was ignored because this word was not in the learned vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case study - text message analysis - SPAM or not?\n",
    "\n",
    "Build classifier to determine was an SMS text message is SPAM or not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"Case-study-text-message-analysis\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-27T14:18:44.510717Z",
     "start_time": "2019-06-27T14:18:44.467813Z"
    }
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "sms = pd.read_csv(\n",
    "    \"s3://tdp-ml-datasets/misc/sms_spam_ham.txt\",\n",
    "    sep=\"\\t\",\n",
    "    encoding=\"ISO-8859-1\",\n",
    "    header=None,\n",
    "    names=[\"label\", \"message\"],\n",
    ")\n",
    "sms[\"labelNum\"] = sms.label.map({\"ham\": 0, \"spam\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-27T14:18:44.527968Z",
     "start_time": "2019-06-27T14:18:44.518460Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5574, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect\n",
    "sms.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-27T14:18:44.555300Z",
     "start_time": "2019-06-27T14:18:44.537525Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5574,)\n",
      "(5574,)\n"
     ]
    }
   ],
   "source": [
    "# review messages and labels\n",
    "X = sms[\"message\"]\n",
    "y = sms[\"labelNum\"]\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-27T14:18:44.575962Z",
     "start_time": "2019-06-27T14:18:44.564379Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       1\n",
       "3       0\n",
       "4       0\n",
       "5       1\n",
       "6       0\n",
       "7       0\n",
       "8       1\n",
       "9       1\n",
       "10      0\n",
       "11      1\n",
       "12      1\n",
       "13      0\n",
       "14      0\n",
       "15      1\n",
       "16      0\n",
       "17      0\n",
       "18      0\n",
       "19      1\n",
       "20      0\n",
       "21      0\n",
       "22      0\n",
       "23      0\n",
       "24      0\n",
       "25      0\n",
       "26      0\n",
       "27      0\n",
       "28      0\n",
       "29      0\n",
       "       ..\n",
       "5544    0\n",
       "5545    0\n",
       "5546    0\n",
       "5547    0\n",
       "5548    0\n",
       "5549    1\n",
       "5550    0\n",
       "5551    0\n",
       "5552    0\n",
       "5553    0\n",
       "5554    0\n",
       "5555    0\n",
       "5556    0\n",
       "5557    0\n",
       "5558    0\n",
       "5559    0\n",
       "5560    0\n",
       "5561    0\n",
       "5562    0\n",
       "5563    0\n",
       "5564    0\n",
       "5565    0\n",
       "5566    0\n",
       "5567    0\n",
       "5568    1\n",
       "5569    1\n",
       "5570    0\n",
       "5571    0\n",
       "5572    0\n",
       "5573    0\n",
       "Name: labelNum, Length: 5574, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-27T14:18:44.595006Z",
     "start_time": "2019-06-27T14:18:44.583382Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4180,)\n",
      "(1394,)\n",
      "(4180,)\n",
      "(1394,)\n"
     ]
    }
   ],
   "source": [
    "# train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-27T14:18:44.891601Z",
     "start_time": "2019-06-27T14:18:44.602583Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>008704050406</th>\n",
       "      <th>0089</th>\n",
       "      <th>0121</th>\n",
       "      <th>01223585236</th>\n",
       "      <th>01223585334</th>\n",
       "      <th>0125698789</th>\n",
       "      <th>02</th>\n",
       "      <th>0207</th>\n",
       "      <th>...</th>\n",
       "      <th>yup</th>\n",
       "      <th>zaher</th>\n",
       "      <th>zealand</th>\n",
       "      <th>zebra</th>\n",
       "      <th>zed</th>\n",
       "      <th>zhong</th>\n",
       "      <th>zoe</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zouk</th>\n",
       "      <th>èn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows × 7446 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00  000  008704050406  0089  0121  01223585236  01223585334  0125698789  \\\n",
       "0   0    0             0     0     0            0            0           0   \n",
       "1   0    0             0     0     0            0            0           0   \n",
       "2   0    0             0     0     0            0            0           0   \n",
       "3   0    0             0     0     0            0            0           0   \n",
       "4   0    0             0     0     0            0            0           0   \n",
       "5   0    0             0     0     0            0            0           0   \n",
       "6   0    0             0     0     0            0            0           0   \n",
       "\n",
       "   02  0207  ...  yup  zaher  zealand  zebra  zed  zhong  zoe  zoom  zouk  èn  \n",
       "0   0     0  ...    0      0        0      0    0      0    0     0     0   0  \n",
       "1   0     0  ...    0      0        0      0    0      0    0     0     0   0  \n",
       "2   0     0  ...    0      0        0      0    0      0    0     0     0   0  \n",
       "3   0     0  ...    0      0        0      0    0      0    0     0     0   0  \n",
       "4   0     0  ...    0      0        0      0    0      0    0     0     0   0  \n",
       "5   0     0  ...    0      0        0      0    0      0    0     0     0   0  \n",
       "6   0     0  ...    0      0        0      0    0      0    0     0     0   0  \n",
       "\n",
       "[7 rows x 7446 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# learn the vocabulary - Vectorize the SMS dataset\n",
    "vect = CountVectorizer()\n",
    "vect.fit(X_train)\n",
    "X_train_dtm = vect.transform(X_train)\n",
    "pd.DataFrame(X_train_dtm.toarray(), columns=vect.get_feature_names())[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-27T14:18:44.997673Z",
     "start_time": "2019-06-27T14:18:44.897725Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>008704050406</th>\n",
       "      <th>0089</th>\n",
       "      <th>0121</th>\n",
       "      <th>01223585236</th>\n",
       "      <th>01223585334</th>\n",
       "      <th>0125698789</th>\n",
       "      <th>02</th>\n",
       "      <th>0207</th>\n",
       "      <th>...</th>\n",
       "      <th>yup</th>\n",
       "      <th>zaher</th>\n",
       "      <th>zealand</th>\n",
       "      <th>zebra</th>\n",
       "      <th>zed</th>\n",
       "      <th>zhong</th>\n",
       "      <th>zoe</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zouk</th>\n",
       "      <th>èn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows × 7446 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00  000  008704050406  0089  0121  01223585236  01223585334  0125698789  \\\n",
       "0   0    0             0     0     0            0            0           0   \n",
       "1   0    0             0     0     0            0            0           0   \n",
       "2   0    0             0     0     0            0            0           0   \n",
       "3   0    0             0     0     0            0            0           0   \n",
       "4   0    0             0     0     0            0            0           0   \n",
       "5   0    0             0     0     0            0            0           0   \n",
       "6   0    0             0     0     0            0            0           0   \n",
       "\n",
       "   02  0207  ...  yup  zaher  zealand  zebra  zed  zhong  zoe  zoom  zouk  èn  \n",
       "0   0     0  ...    0      0        0      0    0      0    0     0     0   0  \n",
       "1   0     0  ...    0      0        0      0    0      0    0     0     0   0  \n",
       "2   0     0  ...    0      0        0      0    0      0    0     0     0   0  \n",
       "3   0     0  ...    0      0        0      0    0      0    0     0     0   0  \n",
       "4   0     0  ...    0      0        0      0    0      0    0     0     0   0  \n",
       "5   0     0  ...    0      0        0      0    0      0    0     0     0   0  \n",
       "6   0     0  ...    0      0        0      0    0      0    0     0     0   0  \n",
       "\n",
       "[7 rows x 7446 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform test set based on learned vocabulary\n",
    "X_test_dtm = vect.transform(X_test)\n",
    "pd.DataFrame(X_test_dtm.toarray(), columns=vect.get_feature_names())[:7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify with multinomial naive bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"Classify-with-multinomial-naive-bayes\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-27T14:18:45.017710Z",
     "start_time": "2019-06-27T14:18:45.003623Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create Naive Bayes model\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-27T14:18:45.034696Z",
     "start_time": "2019-06-27T14:18:45.022673Z"
    }
   },
   "outputs": [],
   "source": [
    "# test set predictions\n",
    "y_pred_class = nb.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-27T14:18:45.050330Z",
     "start_time": "2019-06-27T14:18:45.037996Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9885222381635581"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate predictions\n",
    "metrics.accuracy_score(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-27T14:18:45.068023Z",
     "start_time": "2019-06-27T14:18:45.060996Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1206,    6],\n",
       "       [  10,  172]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create confusion matrix\n",
    "metrics.confusion_matrix(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-27T14:18:45.089983Z",
     "start_time": "2019-06-27T14:18:45.072334Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3415                    No pic. Please re-send.\n",
       "4600    Have you laid your airtel line to rest?\n",
       "574                      Waiting for your call.\n",
       "45             No calls..messages..missed calls\n",
       "4702                     I liked the new mobile\n",
       "4622         Received, understood n acted upon!\n",
       "Name: message, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print message for false positives (ham incorrectly labeled spam)\n",
    "X_test[y_test < y_pred_class]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-27T14:18:45.108469Z",
     "start_time": "2019-06-27T14:18:45.092521Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1875    Would you like to see my XXX pics they are so ...\n",
       "4514    Money i have won wining number 946 wot do i do...\n",
       "684     Hi I'm sue. I am 20 years old and work as a la...\n",
       "5       FreeMsg Hey there darling it's been 3 week's n...\n",
       "5037    You won't believe it but it's true. It's Incre...\n",
       "3419    LIFE has never been this much fun and great un...\n",
       "4069    TBS/PERSOLVO. been chasing us since Sept for£3...\n",
       "2823    ROMCAPspam Everyone around should be respondin...\n",
       "4256    Block Breaker now comes in deluxe format with ...\n",
       "1893    CALL 09090900040 & LISTEN TO EXTREME DIRTY LIV...\n",
       "Name: message, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print message for false negatives (spam incorrectly labeled ham)\n",
    "X_test[y_test > y_pred_class]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-27T14:18:45.335044Z",
     "start_time": "2019-06-27T14:18:45.112861Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "2247",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-d1dc737e7894>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# review specific example\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2247\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    866\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   4373\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4374\u001b[0m             return self._engine.get_value(s, k,\n\u001b[0;32m-> 4375\u001b[0;31m                                           tz=getattr(series.dtype, 'tz', None))\n\u001b[0m\u001b[1;32m   4376\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4377\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mholds_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_bool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 2247"
     ]
    }
   ],
   "source": [
    "# review specific example\n",
    "X_test[2247]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-27T14:18:45.344584Z",
     "start_time": "2019-06-27T14:18:43.292Z"
    }
   },
   "outputs": [],
   "source": [
    "# calculated predicted probabilities for X_test_dtm\n",
    "y_pred_prob = nb.predict_proba(X_test_dtm)[:, 1]\n",
    "y_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-27T14:18:45.349641Z",
     "start_time": "2019-06-27T14:18:43.294Z"
    }
   },
   "outputs": [],
   "source": [
    "# calculate area under the curve score\n",
    "metrics.roc_auc_score(y_test, y_pred_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Evaluate internal probabilities__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-27T14:18:45.357499Z",
     "start_time": "2019-06-27T14:18:43.297Z"
    }
   },
   "outputs": [],
   "source": [
    "# gather feature names\n",
    "X_train_tokens = vect.get_feature_names()\n",
    "len(X_train_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-27T14:18:45.359356Z",
     "start_time": "2019-06-27T14:18:43.300Z"
    }
   },
   "outputs": [],
   "source": [
    "# examine first fifty tokens\n",
    "print(X_train_tokens[0:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-27T14:18:45.363168Z",
     "start_time": "2019-06-27T14:18:43.302Z"
    }
   },
   "outputs": [],
   "source": [
    "# examine last fifty tokens\n",
    "print(X_train_tokens[-50:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-27T14:18:45.366169Z",
     "start_time": "2019-06-27T14:18:43.305Z"
    }
   },
   "outputs": [],
   "source": [
    "# rows = classes, columns = tokens\n",
    "nb.feature_count_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-27T14:18:45.373168Z",
     "start_time": "2019-06-27T14:18:43.307Z"
    }
   },
   "outputs": [],
   "source": [
    "# number of times each token appears in each type of message\n",
    "ham_token_count = nb.feature_count_[0, :]\n",
    "spam_token_count = nb.feature_count_[1, :]\n",
    "\n",
    "tokens = pd.DataFrame(\n",
    "    {\"token\": X_train_tokens, \"ham\": ham_token_count, \"spam\": spam_token_count}\n",
    ").set_index(\"token\")\n",
    "tokens[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-27T14:18:45.378463Z",
     "start_time": "2019-06-27T14:18:43.311Z"
    }
   },
   "outputs": [],
   "source": [
    "# sample from tokens\n",
    "tokens.sample(10, random_state=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-27T14:18:45.382486Z",
     "start_time": "2019-06-27T14:18:43.314Z"
    }
   },
   "outputs": [],
   "source": [
    "# add 1 to each token count to avoid div by 0\n",
    "tokens[\"ham\"] = tokens[\"ham\"] + 1\n",
    "tokens[\"spam\"] = tokens[\"spam\"] + 1\n",
    "tokens.sample(10, random_state=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-27T14:18:45.385607Z",
     "start_time": "2019-06-27T14:18:43.317Z"
    }
   },
   "outputs": [],
   "source": [
    "# covert ham and spam counts into frequencies\n",
    "# divide the number of times a word appears by the total number of observations in that class\n",
    "# these probabilities are used to calculate conditional probability for class designation\n",
    "tokens[\"ham\"] = tokens[\"ham\"] / nb.class_count_[0]\n",
    "tokens[\"spam\"] = tokens[\"spam\"] / nb.class_count_[1]\n",
    "tokens.sample(10, random_state=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-27T14:18:45.391619Z",
     "start_time": "2019-06-27T14:18:43.320Z"
    }
   },
   "outputs": [],
   "source": [
    "# add spam-to-ham ratio\n",
    "tokens[\"spam_ratio\"] = tokens[\"spam\"] / tokens[\"ham\"]\n",
    "tokens.sample(10, random_state=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-27T14:18:45.396269Z",
     "start_time": "2019-06-27T14:18:43.323Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sort by spam_ratio descending to see the 'spammiest' words\n",
    "tokens.sort_values([\"spam_ratio\"], ascending=[False])[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-27T14:18:45.398937Z",
     "start_time": "2019-06-27T14:18:43.327Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sort by spam_ratio ascending to see the least 'spammiest' words\n",
    "tokens.sort_values([\"spam_ratio\"], ascending=[True])[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify with logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"Classify-with-logistic-regression\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-27T14:18:45.402978Z",
     "start_time": "2019-06-27T14:18:43.331Z"
    }
   },
   "outputs": [],
   "source": [
    "# creaet and fit logistic regression model\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train_dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-27T14:18:45.408452Z",
     "start_time": "2019-06-27T14:18:43.333Z"
    }
   },
   "outputs": [],
   "source": [
    "# test set predictions\n",
    "y_pred_class = log_reg.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-27T14:18:45.411812Z",
     "start_time": "2019-06-27T14:18:43.336Z"
    }
   },
   "outputs": [],
   "source": [
    "# evaluate predictions\n",
    "metrics.accuracy_score(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-27T14:18:45.415348Z",
     "start_time": "2019-06-27T14:18:43.338Z"
    }
   },
   "outputs": [],
   "source": [
    "# review predicted probabilities\n",
    "y_pred_prob = log_reg.predict_proba(X_test_dtm)[:, 1]\n",
    "metrics.roc_auc_score(y_test, y_pred_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paramter tuning with CountVectorizer \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"Parameter-tuning-w/-CountVectorizer\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-27T14:18:45.418202Z",
     "start_time": "2019-06-27T14:18:43.342Z"
    }
   },
   "outputs": [],
   "source": [
    "# show default params\n",
    "vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-27T14:18:45.424606Z",
     "start_time": "2019-06-27T14:18:43.344Z"
    }
   },
   "outputs": [],
   "source": [
    "# remove English stop words\n",
    "vect = CountVectorizer(stop_words=\"English\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-27T14:18:45.426491Z",
     "start_time": "2019-06-27T14:18:43.349Z"
    }
   },
   "outputs": [],
   "source": [
    "# expand scope of tokenization. a range of (1,1) makes tokens of single words\n",
    "# a range of (1,2) expands the scope of tokeization so that each pair of words also becomes\n",
    "# a token. this allows for context of word usage to enter the model, but makes the\n",
    "# document-word matrix larger\n",
    "vect = CountVectorizer(ngram_range=(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-27T14:18:45.430835Z",
     "start_time": "2019-06-27T14:18:43.352Z"
    }
   },
   "outputs": [],
   "source": [
    "# ignore terms that appear in X% or more of the documents\n",
    "vect = CountVectorizer(max_df=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-27T14:18:45.432936Z",
     "start_time": "2019-06-27T14:18:43.354Z"
    }
   },
   "outputs": [],
   "source": [
    "# only keep items that appear in X or more documents\n",
    "vect = CountVectorizer(min_df=0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
