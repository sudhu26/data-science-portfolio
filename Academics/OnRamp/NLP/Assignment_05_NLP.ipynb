{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 5\n",
    "\n",
    "__Table of contents__\n",
    "\n",
    "1. [Module 7 walkthrough](#Module-7-walkthrough)\n",
    "1. [Module 8 walkthrough](#Module-8-walkthrough)\n",
    "1. [Assignment 5](#assignment)\n",
    "    1. [Acquire tweets](#Acquire-tweets)\n",
    "    1. [Load tweets](#Load-tweets)\n",
    "    1. [HTML Parser](#HTML-Parser)\n",
    "    1. [Remove username, URL](#Remove-username-URL)\n",
    "    1. [Remove punctuation](#Remove-punctuation)\n",
    "    1. [Remove apostrophes](#Remove-apostrophes)\n",
    "    1. [Word pattern formatting](#Word-pattern-formatting)\n",
    "    1. [Remove hashtags](#Remove-hashtags)\n",
    "    1. [Polarity analysis](#Polarity-analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-18T23:13:30.047888Z",
     "start_time": "2018-11-18T23:13:12.859453Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package sentiwordnet to\n",
      "[nltk_data]     /Users/petersontylerd/nltk_data...\n",
      "[nltk_data]   Package sentiwordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'/search/tweets': {'limit': 450, 'remaining': 450, 'reset': 1542583710}}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import jsonpickle\n",
    "import json\n",
    "import tweepy\n",
    "import html.parser as HTMLParser\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "nltk.download('sentiwordnet')\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "modulePath = os.path.abspath(os.path.join('../../..'))\n",
    "if modulePath not in sys.path:\n",
    "    sys.path.append(modulePath)\n",
    "import config\n",
    "\n",
    "# Standard tweepy API setup\n",
    "\n",
    "auth = tweepy.OAuthHandler(config.apiKey, config.apiSec)\n",
    "auth.set_access_token(config.accessToken, config.accessSec)\n",
    "\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "# Application authentication tweepy setup\n",
    "# Use application-only authentication for higher Twitter API rate limit\n",
    "# Twitter API returns a max of 100 tweets per query\n",
    "# Allows for 450 queries every 15 minutes\n",
    "# So we can gather 45,000 tweets every 15 minutes\n",
    "\n",
    "#Switching to application authentication\n",
    "auth = tweepy.AppAuthHandler(config.apiKey, config.apiSec)\n",
    "\n",
    "#Setting up new api wrapper, using authentication only\n",
    "api = tweepy.API(auth, wait_on_rate_limit = True\n",
    "                 ,wait_on_rate_limit_notify = True)\n",
    " \n",
    "# View rate limit status\n",
    "\n",
    "api.rate_limit_status()['resources']['search']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Module-7-walkthrough'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 7 walkthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-18T23:13:37.433024Z",
     "start_time": "2018-11-18T23:13:37.385484Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@user_@34 Life is great & I like it sooooooooo much. It's whatis life. #life #great#like http://lifeisgreat.com .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/petersontylerd/.pyenv/versions/jupyterMain/lib/python3.6/site-packages/ipykernel_launcher.py:6: DeprecationWarning: The unescape method is deprecated and will be removed in 3.5, use html.unescape() instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# \n",
    "\n",
    "htmlParser = HTMLParser.HTMLParser()\n",
    "\n",
    "tweet = \"@user_@34 Life is great & I like it sooooooooo much. It's whatis life. #life #great#like http://lifeisgreat.com .\"\n",
    "parsedTweet = htmlParser.unescape(tweet)\n",
    "print(parsedTweet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-18T23:13:49.142548Z",
     "start_time": "2018-11-18T23:13:49.136600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@user_@34 Life is great & I like it sooooooooo much. It's whatis life. #life #great#like  .\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "\n",
    "urlPattern = re.compile('http\\S+')\n",
    "tweet_v1 = re.sub(urlPattern, '', parsedTweet)\n",
    "print(tweet_v1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-18T23:13:57.483262Z",
     "start_time": "2018-11-18T23:13:57.479017Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Life is great & I like it sooooooooo much. It's whatis life. #life #great#like  .\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "\n",
    "usernamePattern = re.compile('@\\S+')\n",
    "tweet_v2 = re.sub(usernamePattern, '', tweet_v1)\n",
    "print(tweet_v2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-18T23:14:01.469499Z",
     "start_time": "2018-11-18T23:14:01.464368Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Life is great & I like it so much. It's whatis life. #life #great#like  .\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "\n",
    "wordPattern = re.compile('s[o]+')\n",
    "tweet_v3 = re.sub(wordPattern, 'so', tweet_v2)\n",
    "print(tweet_v3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Module-8-walkthrough'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 8 walkthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-18T23:15:56.399732Z",
     "start_time": "2018-11-18T23:15:56.368573Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/petersontylerd/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "positive score for the word \"happy\": 0.875\n",
      "negative score for the word \"happy\": 0.0\n",
      "neutral score for the word \"happy\": 0.125\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "\n",
    "nltk.download('wordnet')\n",
    "\n",
    "print('positive score for the word \"happy\": {0}'.format(list(swn.senti_synsets('happy','a'))[0].pos_score()))\n",
    "print('negative score for the word \"happy\": {0}'.format(list(swn.senti_synsets('happy','a'))[0].neg_score()))\n",
    "print('neutral score for the word \"happy\": {0}'.format(list(swn.senti_synsets('happy','a'))[0].obj_score()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-18T23:18:29.606078Z",
     "start_time": "2018-11-18T23:18:29.601908Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/petersontylerd/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "Tokens: ['i', 'am', 'happy']\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "sentence = 'i am happy'\n",
    "tokens = nltk.tokenize.word_tokenize(sentence)\n",
    "print('Tokens: {0}'.format(tokens))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-18T23:19:29.663019Z",
     "start_time": "2018-11-18T23:19:28.470738Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/petersontylerd/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('i', 'NN'), ('am', 'VBP'), ('happy', 'JJ')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "\n",
    "from nltk.tag import pos_tag\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "pos_tag(tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NN - noun\n",
    "VBP - verb\n",
    "JJ - adjective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-18T23:20:08.632679Z",
     "start_time": "2018-11-18T23:20:08.285490Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentence has been reduced from 'i am happy' \n",
      " to '['happy']'\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "sentence = 'i am happy'\n",
    "newSentence = []\n",
    "for word in tokens:\n",
    "    if word not in stop:\n",
    "        newSentence.append(word)\n",
    "\n",
    "print('The sentence has been reduced from \\'{0}\\' \\n to \\'{1}\\''.format(sentence, newSentence))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'assignment'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 5\n",
    "\n",
    "* Try cleaning the tweets that you have extracted in the the previous chapter. Apply the above rules and in addition to that apply the below mentioned rules as well:\n",
    "    * Remove Punctuations. Puntuations sometimes don't carry any weight. You can remove them. Try writing a regular expression to remove , from sentences. Dont remove question marks \"?\" or exclamatory marks as they have effect upon any sentence.\n",
    "    * Remove apostrophes and expand the words. For example in the sentence \"It's a great time to code!\" the first word It's can be expanded to 'it is'. You can do this either with regular expressions.\n",
    "    * Create a list of word patterns for word formatting. For example 'gud' should be substitued with 'good'\n",
    "\n",
    "* Calculate the polarity of a sentence and write a progam to calculate the polarity of all the tweets that you have extracted and preprocessed in the previous questions. You progam should also include the below features:\n",
    "\n",
    "    * Tweets have hashtags. Remove the hashtags and then find the polarity of each tweet.\n",
    "\n",
    "    * There might be words that are not present in the sentiwordnet lexicon.\n",
    "    * The program should handle these cases, by giving a zero score for such words.\n",
    "    *Depending on the questions,file uploads or screenshots are necessary to show your work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Acquire-tweets'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acquire tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-14T02:26:30.976683Z",
     "start_time": "2018-11-13T18:13:22.493972Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Find up to 500,000 tweets from the last week containing the word election.\n",
    "# Store in JSON file\n",
    "\n",
    "maxTweets = 500000\n",
    "tweetCount = 0\n",
    "with open('trumpTweets.json','w') as f:\n",
    "    for tweet in tweepy.Cursor(api.search, q = 'trump', tweet_mode = 'extended', lang = 'en').items(maxTweets):\n",
    "        f.write(jsonpickle.encode(tweet._json, unpicklable = False) + '\\n')\n",
    "        tweetCount += 1\n",
    "    print('Downloaded {0} tweets'.format(tweetCount))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Load-tweets'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-19T00:32:26.426389Z",
     "start_time": "2018-11-19T00:31:59.116637Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tweets loaded: 221072\n"
     ]
    }
   ],
   "source": [
    "# Load election tweets into memory\n",
    "\n",
    "data = []\n",
    "with open('./trumpTweets.json', 'r') as jsonFile:\n",
    "    for line in jsonFile:\n",
    "        data.append(json.loads(line))\n",
    "print('Total number of tweets loaded: {0}'.format(len(data)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-19T00:54:37.787786Z",
     "start_time": "2018-11-19T00:54:37.629407Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tweets extracted from json: 221072\n"
     ]
    }
   ],
   "source": [
    "# Unpack all tweets in data\n",
    "\n",
    "tweets = []\n",
    "for item in data:\n",
    "    if 'full_text' in item.keys():\n",
    "        tweet = item['full_text']\n",
    "        tweets.append(tweet)\n",
    "print('Total number of tweets extracted from json: {0}'.format(len(tweets)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-19T00:54:37.854171Z",
     "start_time": "2018-11-19T00:54:37.790044Z"
    }
   },
   "outputs": [],
   "source": [
    "# I only want to look at original tweets, not retweets\n",
    "\n",
    "tweets = [x for x in tweets if not x.startswith('RT ')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-19T00:54:37.861553Z",
     "start_time": "2018-11-19T00:54:37.856176Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@realDonaldTrump Stock goes up, credit to trump , goes down? Blame the Democrats. Got it üëåüèæ\n",
      "\n",
      "This. The crisis is here; it can‚Äôt be avoided, only mitigated. When I look at Trump‚Äôs GOP &amp; their supporters, I see people knowingly and gleefully poisoning my grandchildren and my planet. This is why bipartisanship is BS. I won‚Äôt compromise with murderers. https://t.co/mEYs7IszjB\n",
      "\n",
      "@PrincessBravato Suburban white women who do not have a hard on for Trump like @lindseygraham\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Review first 3 tweets\n",
    "\n",
    "for i in range(3):\n",
    "    print(tweets[i])\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'HTML-Parser'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HTML Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-19T00:54:37.907596Z",
     "start_time": "2018-11-19T00:54:37.863577Z"
    }
   },
   "outputs": [],
   "source": [
    "# \n",
    "import html\n",
    "\n",
    "for ix, tweet in enumerate(tweets):\n",
    "    parsedTweet = html.unescape(tweet)\n",
    "    tweets[ix] = parsedTweet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Remove-username-URL'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove username, URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-19T00:54:38.116890Z",
     "start_time": "2018-11-19T00:54:37.909798Z"
    }
   },
   "outputs": [],
   "source": [
    "# Remove URLs and usernames\n",
    "\n",
    "urlPattern = re.compile(r'(?:\\@|https?\\://)\\S+')\n",
    "for ix, tweet in enumerate(tweets):\n",
    "    parsedTweet = re.sub(urlPattern, '', tweet)\n",
    "    tweets[ix] = parsedTweet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Remove-punctuation'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove punctuation\n",
    "\n",
    "- Remove ','\n",
    "- Keep '?','!'\n",
    "- Remove newline (\\n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-19T00:54:38.315807Z",
     "start_time": "2018-11-19T00:54:38.119083Z"
    }
   },
   "outputs": [],
   "source": [
    "# Replace ellipses with a single space\n",
    "\n",
    "ellipsesPattern = re.compile(r'\\.{3,}')\n",
    "for ix, tweet in enumerate(tweets):\n",
    "    parsedTweet = re.sub(ellipsesPattern, ' ', tweet)\n",
    "    tweets[ix] = parsedTweet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-19T00:54:38.686767Z",
     "start_time": "2018-11-19T00:54:38.317676Z"
    }
   },
   "outputs": [],
   "source": [
    "# Remove all punctuation except '?', '!', '#',and apostrophes\n",
    "\n",
    "punctuationPattern = re.compile(r'[^\\w\\d\\s?!\\'#]+')\n",
    "for ix, tweet in enumerate(tweets):\n",
    "    parsedTweet = re.sub(punctuationPattern, '', tweet)\n",
    "    tweets[ix] = parsedTweet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-19T00:54:39.241497Z",
     "start_time": "2018-11-19T00:54:38.688322Z"
    }
   },
   "outputs": [],
   "source": [
    "# Remove unnecessary white space, newlines and tabs\n",
    "\n",
    "stripPattern = re.compile(r'\\s+')\n",
    "for ix, tweet in enumerate(tweets):\n",
    "    parsedTweet = re.sub(stripPattern, ' ', tweet).strip()\n",
    "    tweets[ix] = parsedTweet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-19T00:54:39.249587Z",
     "start_time": "2018-11-19T00:54:39.243443Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Stock goes up credit to trump goes down? Blame the Democrats Got it',\n",
       " 'This The crisis is here it cant be avoided only mitigated When I look at Trumps GOP their supporters I see people knowingly and gleefully poisoning my grandchildren and my planet This is why bipartisanship is BS I wont compromise with murderers',\n",
       " 'Suburban white women who do not have a hard on for Trump like',\n",
       " 'I am so weary of how often you lie about this It is early but still not going to work Trumps Tax Cut Was Supposed to Change Corporate Behavior Heres What Happened',\n",
       " 'Ummmmmmm no Trump claims he tried to salvage trip to French cemetery for US troops POLITICO',\n",
       " 'We couldnt look more closely if we tried Every single story MSM gives us proves they are united with us against Trump',\n",
       " \"Putin will send a Putin bear to Trump in his new prison surrounding's And will make sure Ivan is his daddy I mean cellmate\",\n",
       " 'Donald Trump gets back to the United States and someone explains what they were saying in Europe',\n",
       " 'Before tRUMP the US would have been embarrassed to ally itself with Russia and North Korea And',\n",
       " \"They wouldn't have done this when Obama was in office or Bush come to that but with Trump in they feel he'll back them\",\n",
       " 'Trump is vulgar but EU has always been under US heel George Galloway',\n",
       " 'Wrong person to use in gif sublimally a hateful person Next time use the trump bear',\n",
       " 'Europes Calculations Shift on Trump Second Term',\n",
       " 'Trump clashes with globalist European leaders Trudeau as he embraces nationalism',\n",
       " 'Every day all day Thank you',\n",
       " 'Inside the Body of King Henry VIII Full Tudor Documentary via Ah nothing like finding about the health of some famous person of the past Imagine if Hillary had been elected? Do you think Henry could keep up wTrump?',\n",
       " 'This isnt going to make anyone drink Trump wine I guess Macron isnt your buddy anymore Did someone get his feefees hurt?',\n",
       " 'Didnt Trump fire someone after his last appearance with Putin?',\n",
       " \"President Trump took credit for retiring Jeff Flake He didn't account for Democrat Kyrsten Sinema who is about to make history on multiple fronts\",\n",
       " 'If you actually read this short piece you would understand the cause of the increase Hint Not Trump The FBI says although the number of attacks has increased so has the number of law enforcement agencies reporting hatecrime data',\n",
       " 'Mueller seeking more details on Nigel Farage key Russia inquiry target says',\n",
       " 'WHY TRUMP IS RIGHT ON CALIFORNIA WILDFIRES',\n",
       " \"He asked a question and the answer was You are a terrible person or some gibberish like that Had Trump actually answered the question the whole thing wouldn't have happened But Trump is as well behaved and patient as my 2 year old nephew\",\n",
       " 'Dictator talk Trump DEMANDS RESPECT from Jim Acosta April Ryan while insulting them talking abt April Ryan 1st',\n",
       " \"Oh dear Said no one CNN sues Trump over Jim Acosta's credential suspension\",\n",
       " 'And of course all of you Trump supporters are in here defending literal Nazis',\n",
       " \"It's as if EVERYONE in Trump's circle has NEVER come into contact with our Constitution\",\n",
       " 'DJ Trump',\n",
       " 'Mueller seeking more details on Nigel Farage key Russia inquiry target says',\n",
       " 'You sound like a Trump bashing liberal the real issue is the poor young soldiers made to fight and die for the upper class and not about Trump?',\n",
       " 'The Tories are throwing us off a cliff Trump is a monstrous orange bollock but I do have a carrot that looks a bit like Windy Miller #trumpton #thatslife',\n",
       " 'Just putting this here',\n",
       " 'The argument against Pekisi is short sighted she cant be vilified anymore than she has been She took the fire held her ground She lead the Dems to the majority under a constant barrage She knows how to lead how to fight and more importantly how to win in the age of Trump',\n",
       " 'Trump is Russia and his wife is illegal!',\n",
       " 'The candidate Cernovich claims was Trump shy held rallies with him and campaigned with his public endorsement In nearly every R district in which there was a HouseSenate race featuring a Republican Trump endorsed and one he snubbed the perceived Never Trumper did better',\n",
       " \"I like seeing Trump on the defensive Glad he's paying close attention to what most of the world thinks about him #FIRETRUMP\",\n",
       " 'With pleasure WE serve at the request of the President President Trump Thank you',\n",
       " \"Trump won't meet Mueller for an interview because his lawyers know he lacks the intelligence to avoid self incriminating statements Mueller on the other hand seems confident that the President and his lawyers won't be able satisfactorily answer them in writing\",\n",
       " 'White Like Trump white',\n",
       " 'This is why trump supposedly endorsed her it was bait and the kids of death',\n",
       " 'I doubt it Dave Brat 100 MAGA got tossed in VA I see NOTHING that says Rs are going to be able to do anything in 2020 And Trump may well lose Especially if a significant # of people arent held accountable for spying on the Trump campaignattempt to subvert the election',\n",
       " \"DOJ's antitrust chief says Trump tweets 'don't affect our decisions' a day after Trump slams Comcast\",\n",
       " 'TrumpZinke want to destroy historical records on endangered species marine conservation oil and gas leases mining dams critical habitats land acquisitions etc These should be archived not destroyed Send protest to the National Archives',\n",
       " 'He must be gutted Trump has got bigger hands than him',\n",
       " 'Is fake news becoming mainstream?',\n",
       " 'Good riddance She was a shill and probably too mainstream for Trump He prefers a little more obvious groveling and willing complicity in his efforts to dismantle democracy and remake America in his image',\n",
       " \"12 Mueller's coming for you Ha ha ha ha ha!Mueller seeking more details on Nigel Farage key Russia inquiry target says\",\n",
       " 'The world leaders really let Trump have it! The entire message was to him',\n",
       " \"Mueller has NO integrity he's a despicable fraud out to get Trump\",\n",
       " 'expansion of cheaper and slimmer coverage alternatives to Obamacare The laws new enrollment period which opened almost two weeks ago could show just how much states supporting the Affordable Care Act can insulate themselves from President Donald Trumps efforts to weaken it',\n",
       " 'Lmaooooooooo trump',\n",
       " 'Had an argument with a Trump supporter about how much hate Trump has caused and the dude had the audacity to try and argue against that lol',\n",
       " 'Ohhh Guess Chuck forgot that no one can trust a word that comes out of Trumps mouthOr maybe he thinks we have forgotten We have not! Whitaker needs to recuse',\n",
       " 'More of trumps BS with tax payers money When he didnt even honor the Vets in Paris',\n",
       " 'Trump Delivers Touching Tribute To Fallen Heroes Of WWE',\n",
       " 'WAR TRIGGERS NATO has joined Donald Trump in his condemnation of Emmanuel Macrons demands for a real European army to protect the Continent against the United States China and Russia',\n",
       " \"St Marcy of the two faces Rails against untruth in the press while supporting Trump who is closing in on his 6000th lie How's the invasion Marcy? How about that middle class taxcut you were working nite day on? No climate change issue right? just lying political scientists\",\n",
       " 'Mueller seeking more details on Nigel Farage key Russia inquiry target says',\n",
       " \"Many companies said they'd use the savings from Trump's tax cuts to create jobs But the 1000 largest public companies have actually reduced employment They've announced the elimination of 140000 jobs almost double the 73000 they said they'd create\",\n",
       " 'Woodward No Evidence Of Trump Russia Collusion',\n",
       " \"Because you're NOT supposed to wave ANYTHING off a ride ! Duh!! It's dangerous AND POSTED EVERYWHERE! Stupid trump Trump puppets !\",\n",
       " 'Trump! Thank you Next',\n",
       " 'Stephanie Cliffords life has spiraled so far down the toilet Shes broke divorced losing her child and is being forced to pay Trumps legs fees The poor thing',\n",
       " \"I'm not a Trump supporter but I was under the impression that the White House decided who gets in PERIOD If I can't get in there because I'm not an employee of a global corporation then when and where did the criteria for allowing people into the White House come from?\",\n",
       " 'I did not see that coming',\n",
       " 'Economy is doing great Come out of mommys basement get your head out of your anal cavity look around The only crook in the last election was the career crooked criminal Hillary There is so much proof regarding her corruption and not one iota of evidence against Trump',\n",
       " \"I'm Jewish AND TrumpHitlerism Hitler didn't start out with ovens Trump is following the Hitler playbook attacking press conspiracy theories lying to sway public opinion attacking migrants attempting to circumvent the Constitution closing borders and more\",\n",
       " 'From a delerious Donald Trump to a amazing Jimmy Carter Nobody can serve two masters The Thrashed Hippalectryon',\n",
       " 'Three years in a row hmmmm how long has Trump been in the headlines now? FBI report shows spike in hate crimes for third year in a row',\n",
       " 'Who has the trademark on this and whos making the money tRump?',\n",
       " 'The leader himself is a drag and a boon Trump added Obama voters and subtracted other voters How do you find the sweet spot?',\n",
       " 'Go Trump Go ! #MAGA',\n",
       " 'Trump drives a wedge between allies and brings up German WWII invasion via',\n",
       " 'Nah its bludgeoning about having to vote Trump When people say you cant even writein but are morally obligated to vote GOP over DNC just bc they pretend to care about the unborn thats how it comes to this',\n",
       " \"To be clear I don't advocate either side do this but to act as if this is just a Trump thing is just partisan and disingenuous\",\n",
       " \"DOJ's antitrust chief says Trump tweets 'don't affect our decisions' a day after Trump slams Comcast\",\n",
       " 'Trump Warns That Florida Recount Could Set Dangerous Precedent of Person with Most Votes Winning',\n",
       " \"The mayor of Livermore California explains Trumps popularity and success This is perhaps the best explanation for Trump's popularity Awesome article All Patriots read this\",\n",
       " \"Demented and Depraved DingleberryDonald tRump The Treasonous Fascist Rabidly Racist and Monstrously Evil Piece of Shit isn't fit to shine the shoes of President Emmanuel Macron of France! Vive La France\",\n",
       " \"GFY!! OBAMA and his professional racebaiting wife are to blame Then there's Hillary Clinton and her Super Predators I challange Intercept to cite ONE example of Trump's racism corruption antidemocratic actions JUST ONE!\",\n",
       " \"Trump's motto is the literal opposite of mail carriers Whether it's snow rain heat or gloom of night they will all keep Trump from completion of his appointed task\",\n",
       " \"CNN sues President Trump and top White House aides for barring Jim Acosta CNN doesb't CNN have better things to do? report Real News please! not drama laced\",\n",
       " 'Also the ones Snipes has hidden in her trunk?',\n",
       " 'This is not the first time Acosta has behaved rudely in a press event Taken as an aggregate he is going beyond his 1st amendment rights and is infringing on the rights Trump does not have to put up with harassment any more than you or I do #CNN can send someone else',\n",
       " 'How President Trump spends his time after hours',\n",
       " 'I saw that A telling moment of a deep respect and friendship compared to the revulsion of Trump by the rest of the world',\n",
       " \"DOJ's antitrust chief says Trump tweets 'don't affect our decisions' a day after Trump slams Comcast\",\n",
       " 'The could vote now to fund the #Wall now if they want to But they wont #Republicans do not keep their word Trump does but the establishment dose not #Obamacare repeal? #debt?',\n",
       " 'Americas Got Talent finalist I was kicked off tour after posting proTrump photo via',\n",
       " \"Trump literally bailed on honoring veterans at Arlington National Cemetery on Veteran's Day because of rain He didn't want everyone to see his shitstorm of a combover That's how vain and narcissistical he is But yeah Colin Kaepernick took a knee\",\n",
       " 'If Trump aka #MrChaos really wanted to go to the WWI Memorial he would have found a way!',\n",
       " 'You dont get tired of being ridiculous The US wasnt a utopia and its not yet a dystopia But even for us thats a lot of politically motivated violence Trump encourages his crowds to chant Lock her up about women that they target for hate No crime just prison',\n",
       " \"Reporter details CNN's First Amendment lawsuit against the Trump White House and publicly calls out defendants by name #Sanders\",\n",
       " 'He picked up his remarks from commentary on yesterdays Fox News I saw it at gym yesterday Exact words used by trump',\n",
       " \"Here's another troll\",\n",
       " \"Urging Florida To Ignore Military Votes Fits Trump's True Pattern With The Troops\",\n",
       " \"Oh boy you'd really take Trump in exchange? Feel free!\",\n",
       " 'At least I didnt vote for the lesser of two evils Because doing that is how pushed politics far enough to the right to give someone like Trump a window of opportunity',\n",
       " 'Good news is so rare these days moments like this should be treasured Mueller seeking more details on Nigel Farage key Russia inquiry target says',\n",
       " 'Trump sings to Hillary Clinton']"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Remove-apostrophes'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove apostrophes\n",
    "\n",
    "- Remove apostrophes and expand words\n",
    "    - \"It's\" becomes \"It is\", however \"Trump's\" stays \"Trump's\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It's, what's, whats, that's, thats\n",
    "- do a search through corpus for the rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Word-pattern-formatting'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word pattern formatting\n",
    "\n",
    "- Condense extended strings of vowels and consonants down to form correctly spelled word\n",
    "    - \"Gooooooood\" becomes \"Good\"\n",
    "    - \"Realllllly\" becomes \"Really\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-18T23:14:01.469499Z",
     "start_time": "2018-11-18T23:14:01.464368Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Life is great & I like it so much. It's whatis life. #life #great#like  .\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "\n",
    "wordPattern = re.compile('s[o]+')\n",
    "tweet_v3 = re.sub(wordPattern, 'so', tweet_v2)\n",
    "print(tweet_v3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Remove-hashtags'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Polarity-analysis'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polarity analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
